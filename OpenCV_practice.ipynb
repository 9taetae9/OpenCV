{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('lena512.bmp')\n",
    "\n",
    "if img is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "cv.imshow('image', img)\n",
    "cv.waitKey()\n",
    "#Mat imread(const String& filename, int flags=IMREAD_COLOR); flags=>영상 파일불러올시(컬러모드,영상크기 지정)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(img1)  <class 'numpy.ndarray'>\n",
      "img1.shape:  (512, 512)\n",
      "img1 is a grayscale image\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def func1():\n",
    "    img1=cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img1 is None:\n",
    "        print('failed!')\n",
    "        return \n",
    "    \n",
    "    print('type(img1) ', type(img1))\n",
    "    print('img1.shape: ', img1.shape)\n",
    "    \n",
    "    if len(img1.shape)==2:\n",
    "        print('img1 is a grayscale image')\n",
    "    elif len(img1.shape)==3:\n",
    "        print('color')\n",
    "        \n",
    "    cv.imshow('img1',img1)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "func1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2():\n",
    "    img1 = np.empty((480,640), np.uint8) #grayscale\n",
    "    img2 = np.zeros((480,640,3), np.uint8) #color image\n",
    "    img3 = np.ones((480,640),np.int32) #1's matrix\n",
    "    img4 = np.full((480,640), 0, np.float32) #fill with 0,0\n",
    "    \n",
    "    mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func3():\n",
    "    img1 = cv.imread('lena512.bmp')\n",
    "    \n",
    "    img2=img1\n",
    "    img3=img1.copy()\n",
    "    \n",
    "    img1[:, :]=(0,255,255) #yello (b,g,r) 순\n",
    "    \n",
    "    cv.imshow('img1',img1)# =>노랑\n",
    "    cv.imshow('img2', img2)# =>노랑\n",
    "    cv.imshow('img3', img3) #=>사진\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "func3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-a10146f78d83>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-a10146f78d83>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def func4():\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def func4():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-abfdd1ec171b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-abfdd1ec171b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def func5() #=>반전 시켜보기 255-원래값\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def func5() #=>반전 시켜보기 255-원래값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat1\n",
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n",
      "mat2\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "mat3\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "mat4\n",
      "[[ 0  2  4  6]\n",
      " [ 8 10 12 14]\n",
      " [16 18 20 22]]\n"
     ]
    }
   ],
   "source": [
    "#행렬연산\n",
    "def func6():\n",
    "    mat1=np.ones((3,4),np.int32)\n",
    "    mat2=np.arange(12).reshape(3,4)\n",
    "    mat3=mat1+mat2\n",
    "    mat4=mat2*2\n",
    "    print(\"mat1\")\n",
    "    print(mat1)\n",
    "    print(\"mat2\")\n",
    "    print(mat2)\n",
    "    print(\"mat3\")\n",
    "    print(mat3)\n",
    "    print(\"mat4\")\n",
    "    print(mat4)\n",
    "    \n",
    "func6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap.get(...) 현재 열려있는 카메라 장치 또는 동영상 파일로부터 여러가지정보를 받아 오기 위해 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame width:  640\n",
      "frame height:  480\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print('failed')\n",
    "    sys.exit()\n",
    "    \n",
    "print(\"frame width: \", int(cap.get(cv.CAP_PROP_FRAME_WIDTH)))\n",
    "print(\"frame height: \", int(cap.get(cv.CAP_PROP_FRAME_HEIGHT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame= cap.read() \n",
    "# ret, frame= cap.read(): Here, cap is assumed to be an OpenCV video capture object (though it isn't defined in the snippet). \n",
    "#The read() method reads a frame from the video source (could be a webcam or video file). It returns two values:\n",
    "# ret (short for 'return'): A boolean value. If a frame is successfully grabbed, it is True, otherwise, it is False.\n",
    "# frame: The grabbed frame, if any.\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    inversed = ~frame #이미지 반전\n",
    "    \n",
    "    cv.imshow('frame',frame)\n",
    "    cv.imshow('inversed', inversed)\n",
    "    \n",
    "    if cv.waitKey(10) == 27: #27==ESC key\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "cap=cv.VideoCapture('tree.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('failed')\n",
    "    sys.exit()\n",
    "    \n",
    "print('width',int(cap.get(cv.CAP_PROP_FRAME_WIDTH)))\n",
    "print('height',int(cap.get(cv.CAP_PROP_FRAME_HEIGHT)))\n",
    "print('count',int(cap.get(cv.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "fps = cap.get(cv.CAP_PROP_FPS)\n",
    "print('FPS: ',fps)\n",
    "delay=round(1000/fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv.VideoCapture('tree.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"failed\")\n",
    "    sys.exit()\n",
    "#원본동영상 open  \n",
    "w=round(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "h=round(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "fps=cap.get(cv.CAP_PROP_FPS)\n",
    "\n",
    "fourcc=cv.VideoWriter_fourcc(*'DVIX')\n",
    "delay=round(1000/fps)\n",
    "\n",
    "outputVideo=cv.VideoWriter('tree.avi', fourcc, fps, (w,h))\n",
    "if not outputVideo.isOpened():\n",
    "    print('failed!')\n",
    "    sys.exit()\n",
    "    \n",
    "while True:\n",
    "    ret, frame= cap.read() \n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    inversed = ~frame #이미지 반전\n",
    "    outputVideo.write(inversed)\n",
    "    \n",
    "    cv.imshow('frame',frame)\n",
    "    cv.imshow('inversed', inversed)\n",
    "    \n",
    "    if cv.waitKey(delay) == 27: #27==ESC key\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.full((400,400,3),255,np.uint8)\n",
    "\n",
    "cv.line(img, (50,50),(200,50),(0,0,255))\n",
    "cv.line(img, (50,100),(200,100),(255,0,255),3)\n",
    "cv.line(img, (50,150),(200,150),(255,0,0),10)\n",
    "\n",
    "cv.line(img, (250,50),(350,100),(0,0,255),1,cv.LINE_4)\n",
    "cv.line(img, (250,70),(350,120),(255,0,255),1,cv.LINE_8)\n",
    "cv.line(img, (250,90),(350,140),(255,0,0),1,cv.LINE_AA)\n",
    "\n",
    "cv.arrowedLine(img, (50,200),(150,200),(0,0,255),1)\n",
    "cv.arrowedLine(img, (50,250),(350,250),(255,0,255),1)\n",
    "cv.arrowedLine(img, (50,300),(350,300),(255,0,0),1,cv.LINE_8,0,0.05)\n",
    "\n",
    "\n",
    "cv.imshow('img',img)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('lena512.bmp')\n",
    "if img is None :\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "    \n",
    "cv.namedWindow('img')\n",
    "cv.imshow('img',img)\n",
    "\n",
    "while True:\n",
    "    keycode = cv.waitKey()\n",
    "    if keycode == ord('i') or keycode == ord('I'):\n",
    "        img= ~img\n",
    "        cv.imshow('img',img)\n",
    "    elif keycode ==27 or keycode == ord('q') or keycode == ord('Q'):\n",
    "        break\n",
    "        \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global oldx, oldy\n",
    "    \n",
    "    if event==cv.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x,y #마지막 위치 업데이트\n",
    "        print('Event_LBUTTONDOWN: %d %d' %(x,y))\n",
    "        \n",
    "    elif event == cv.EVENT_LBUTTONUP:#클릭버튼 떄기\n",
    "        print('EVENT_LBUTTONUP: %d %d ' %(x,y))\n",
    "        \n",
    "    elif event == cv.EVENT_MOUSEMOVE:\n",
    "        if flags & cv.EVENT_FLAG_LBUTTON: #true 이면 드래깅중\n",
    "            cv.line(img, (oldx,oldy),(x,y),(0,255,255),2)\n",
    "            cv.imshow('img',img)\n",
    "            oldx, oldy = x,y\n",
    "            \n",
    "img = cv.imread('lena512.bmp')\n",
    "    \n",
    "if img is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "        \n",
    "cv.namedWindow('img')\n",
    "cv.setMouseCallback('img',on_mouse)\n",
    "    \n",
    "cv.imshow('img',img)\n",
    "cv.waitKey() #키보드 입력시 종료\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "#트렉바 사용하기 \n",
    "#사용자가 마우스를 이용하여 트랙바 위치를 조정하면 그에 해당하는 밝기로 영상이 변경됨\n",
    "def saturated(value):\n",
    "    if value > 255:\n",
    "        value=255\n",
    "    elif value<0:\n",
    "        value=0\n",
    "        \n",
    "    return value\n",
    "\n",
    "def on_level_change(pos):\n",
    "    img[:]=saturated(pos*16)\n",
    "    cv.imshow('image',img)\n",
    "    \n",
    "img=np.zeros((400,400),np.uint8)\n",
    "\n",
    "cv.namedWindow('image')\n",
    "cv.createTrackbar('level','image',0,16,on_level_change)\n",
    "\n",
    "cv.imshow('image',img)\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='mydata.json'\n",
    "def writeData():\n",
    "    name='Jane'\n",
    "    age=10\n",
    "    pt1=(100,200)\n",
    "    scores=(80, 90, 50)\n",
    "    mat1=np.array([[1.0, 1.5],[2.0,3.2]], dtype=np.float32)\n",
    "    \n",
    "    fs=cv.FileStorage(filename, cv.FILE_STORAGE_WRITE)\n",
    "    \n",
    "    if not fs.isOpened():\n",
    "        print('File open failed!')\n",
    "        return \n",
    "    \n",
    "    fs.write('name',name)\n",
    "    fs.write('age',age)\n",
    "    fs.write('point',pt1)\n",
    "    fs.write('scores',scores)\n",
    "    fs.write('data',mat1)\n",
    "    \n",
    "    fs.release()\n",
    "    \n",
    "#데이터 파일을 읽어 오기 위하여 FileStorage 객체를 생성하고 읽기모드로 열어야함\n",
    "#XML/YAML/JOSN 파일을 읽기 모드로 열면 파일 전체를 분석하여 계층적 구조를 갖는 노드 집합을 구성\n",
    "#-Node는 이름과 값으로 구성되어 있는 하나의 데이터를 의미\n",
    "#-특정 이름으로 저장되어 있는 Node에 접근하려면 getNode() 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 파일 불러오기\n",
    "def readData():\n",
    "    fs=cv.FileStorage(filename, cv.FILE_STORAGE_READ)\n",
    "    \n",
    "    if not fs.isOpened():\n",
    "        print('File open failed!')\n",
    "        return\n",
    "    \n",
    "    name = fs.getNode('name').string()\n",
    "    age=int(fs.getNode('age').real())\n",
    "    pt1=tuple(fs.getNode('point').mat().astype(np.int32).flatten())\n",
    "    mat1=fs.getNode('data').mat()\n",
    "    \n",
    "    fs.release()\n",
    "    \n",
    "    print('name:', name)\n",
    "    print('age:', age)\n",
    "    print('point', pt1)\n",
    "    print('scores:', scores)\n",
    "    print('data:')\n",
    "    print(mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#유용한 기능\n",
    "#마스크 연산 \n",
    "#임의의 모양을 갖는 roi 설정을 위하여 일부 행렬 연산 함수에 대하여 마스크 연산을 지원함\n",
    "#보통 입력 영상과 크기가 같고 깊이가 cv_8u인 마스크 영상을 함께 인자로 전달 받음.\n",
    "#일반적으로 사람의 눈으로 구분이 쉽도록 픽셀 값을 0 또는 255로 구성된 흑백 영상을 사용한다.\n",
    "\n",
    "def mask_setTo():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_COLOR)\n",
    "    mask = cv.imread('mask_smile.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None or mask is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    src[mask>0]=(0,255,255) #b,g,r\n",
    "    #사용된 mask 영상은 중앙에 웃는 얼굴 부분이 흰색 나머지 영역은 픽셀 값에 해당하는 검은 색\n",
    "    #마스크 영상에서 흰색으로 표시된 영역에 대해서만 영상 픽셀이 노란색으로 설정된 것을 확인 가능\n",
    "    cv.imshow('src',src)\n",
    "    cv.imshow('mask',mask)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "mask_setTo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_copyTo():\n",
    "    src = cv.imread('airplane.bmp',cv.IMREAD_COLOR)\n",
    "    mask = cv.imread('mask_plane.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    dst = cv.imread('field.bmp', cv.IMREAD_COLOR)\n",
    "    #mask는 grayscale 영상으로, 비행기가 있는 위치에서만 픽셀값이 255이고 나머지 영역은 픽셀값이 0\n",
    "    #dst 영상은 field.bmp 파일에 저장된 들판\n",
    "    if src is None or mask is None or dst is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    dst[mask>0]==src[mask>0] \n",
    "    #Mask 영상에서 흰색으로 표현된 위치에서만 src 영상의 픽셀값이 dst 영상으로 복사됨\n",
    "    \n",
    "    cv.imshow('src',src)\n",
    "    cv.imshow('dst',dst)\n",
    "    cv.imshow('mask',mask)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "mask_copyTo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TickMeter : 연산시작 측정\n",
    "def time_inverse():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    dst = np.empty(src.shape, dtype=src.dtype)\n",
    "    \n",
    "    tm = cv.TickMeter()\n",
    "    tm.start()\n",
    "    \n",
    "    for y in range(src.shape[0]):\n",
    "        for x in range(src.shape[1]):\n",
    "            dst[y,x]=255-src[y,x]\n",
    "            \n",
    "    tm.stop()\n",
    "    print('Image inverse implementation took %4.3f ms.' % tm.getTimeMilli())\n",
    "    \n",
    "    cv.imshow('src',src)\n",
    "    cv.imshow('dst', dst)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "time_inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TickMeter: 연산시작 측정\n",
    "def time_inverse_numpy():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    tm = cv.TickMeter()\n",
    "    tm.start()\n",
    "\n",
    "    # Use numpy operation for inversion\n",
    "    dst = 255 - src\n",
    "\n",
    "    tm.stop()\n",
    "    print('Image inverse implementation took %4.3f ms.' % tm.getTimeMilli())\n",
    "\n",
    "    cv.imshow('src', src)\n",
    "    cv.imshow('dst', dst)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "time_inverse_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TickMeter: 연산시작 측정\n",
    "def time_inverse_numpy2():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "\n",
    "    tm = cv.TickMeter()\n",
    "    tm.start()\n",
    "\n",
    "    # Use numpy bitwise NOT operation for inversion\n",
    "    dst = ~src\n",
    "\n",
    "    tm.stop()\n",
    "    print('Image inverse implementation took %4.3f ms.' % tm.getTimeMilli())\n",
    "\n",
    "    cv.imshow('src', src)\n",
    "    cv.imshow('dst', dst)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "time_inverse_numpy2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum:  32518590\n",
      "Mean:  124\n"
     ]
    }
   ],
   "source": [
    "def useful_func():\n",
    "    img=cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "    \n",
    "    sum_img = np.sum(img)\n",
    "    mean_img=np.mean(img, dtype=np.int32)\n",
    "    print('Sum: ',sum_img)\n",
    "    print('Mean: ',mean_img)\n",
    "    \n",
    "useful_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minVal is 25.0 at (508, 71)\n",
      "maxVal is 245.0 at (116, 273)\n"
     ]
    }
   ],
   "source": [
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "minVal, maxVal, minPos, maxPos = cv.minMaxLoc(gray)\n",
    "print('minVal is',minVal, 'at', minPos)\n",
    "print('maxVal is', maxVal, 'at', maxPos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Normalization 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src:  [[-1.  -0.5  0.   0.5  1. ]]\n",
      "dst:  [[  0  64 128 191 255]]\n"
     ]
    }
   ],
   "source": [
    "src=np.array([[-1,-0.5,0,0.5,1]], dtype=np.float32)\n",
    "dst=cv.normalize(src, None, 0, 255, cv.NORM_MINMAX, cv.CV_8U)\n",
    "print('src: ', src)\n",
    "print('dst: ', dst)\n",
    "\n",
    "#-1~1 의 실수로 구성된 1x5행렬을 0~255사이의 정수 행렬로 반환하는 경우\n",
    "#최솟값은 0, 최대값은 255가 되로록 크기를 조정하고, 결과행렬의 타입이 CV_8U가 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round(2.5) is 2\n",
      "round(2.51) is 3\n",
      "round(3.499) is 3\n",
      "round(3.5) is 4\n"
     ]
    }
   ],
   "source": [
    "print('round(2.5) is',round(2.5))\n",
    "print('round(2.51) is',round(2.51))\n",
    "print('round(3.499) is',round(3.499))\n",
    "print('round(3.5) is',round(3.5))\n",
    "#소수점 아래가 0.5보다 크면 올림 작으면 내림. 정확히 0.5일 경우 가장 가까운 짝수로 반올림 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상의 밝기 조절\n",
    "\n",
    "#### 원소 자료형이 가질 수 있는 값의 범위를 벗어나는 경우 해당 자료형의 최솟값 또는 최댓값으로 원소 값을 설정하는 연산을 OpenCV에서 포화(saturate) 연산이라고 부름.\n",
    "#### 실제로 영상의 밝기 조절을 구현할 때에는 아래와 같이 포화 연산을 함께 고려한 수식을 사용해야 함.\n",
    "#### dst(x,y) = saturate(src(x,y)+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness1():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    dst = cv.add(src, 100) #각각 100씩 더한다! (saturate 자동 적용)\n",
    "    dst2= cv.subtract(src, 100)\n",
    "    cv.imshow('src',src)\n",
    "    cv.imshow('dst',dst)\n",
    "    cv.imshow('dst2',dst2)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "brightness1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영상의 밝기 조절 직접 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness2():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    dst = np.empty(src.shape, src.dtype) #사용자가 직접 결과 영상의 픽셀값을 설정하기 위해서는 반드시 적절한 크기와 \n",
    "                                        #타입의 결과 영상을 미리 생성해야함\n",
    "    for y in range(src.shape[0]): #이중 for문을 이용해 영상 전체를 스캔할 수 있음\n",
    "        for x in range(src.shape[1]):\n",
    "            dst[y,x]=src[y,x]+100  \n",
    "    \n",
    "    cv.imshow('src',src)\n",
    "    cv.imshow('dst',dst)  #=> 결과가 add와 subtract 함수를 사용했을 때와는 다른 기대하지 않은 결과가 나옴\n",
    "    #why? => dst[y,x]=src[y,x]+100 과정에는 자동으로 saturate 연산, 즉 포화 연산을 지원하지 않기 떄문에 직접 처리해주어야함.\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "brightness2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saturated(value): #포화 연산 함수\n",
    "    if value>255:\n",
    "        value = 255\n",
    "    elif value<0:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "def brightness3():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    dst = np.empty(src.shape, src.dtype)\n",
    "    for y in range(src.shape[0]): \n",
    "        for x in range(src.shape[1]):\n",
    "            dst[y,x]=saturated(src[y,x]+100)  \n",
    "    \n",
    "    cv.imshow('src',src)\n",
    "    cv.imshow('dst',dst)  \n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "brightness3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#트랙바를 이용한 영상의 밝기 조절\n",
    "\n",
    "def brightness4():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    def update(pos):\n",
    "        dst = cv.add(src, pos)\n",
    "        cv.imshow('dst',dst)\n",
    "        \n",
    "    cv.namedWindow('dst')\n",
    "    cv.createTrackbar('Brightness', 'dst', 0, 100, update)\n",
    "    update(0)\n",
    "    \n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "brightness4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "### 영상에서 원하는 정보만 통과시키고 원치 않는 정보는 걸러내는 작업\n",
    "### 영상의 필터링은 보통 마스크(mask)라고 부르는 작은 크기의 행렬을 이용\n",
    "\n",
    "## mask(마스크)\n",
    "\n",
    "### 필터링의 성격을 정의하는 행렬\n",
    "### kermel, window라고도 부름\n",
    "### mask 자체를 filter라고 부르기도 함\n",
    "\n",
    "## 필터링 연산 방법\n",
    "\n",
    "### 그림에 표시한 다양한 필터 마스크에서 진한 색으로 표시한 위치는 anchor point(고정점)\n",
    "### 고정점은 현재 필터링 작업을 수행하고 있는 기준 픽셀 위치를 나타내고, 대부분의 경우 마스크 행렬을 정중앙을 고정점으로 사용\n",
    "### 연산의 결과는 마스크 행렬의 모양과 원소 값에 의해 결정\n",
    "#### 마스크 행렬을 어떻게 정의하는가에 따라 영상의 느낌을 바꿈\n",
    "#### 잡음 제거, 에지 성분만 나타나도록 만드는 등..\n",
    "\n",
    "### 마스크 행렬의 모든 원소에 대하여 마스크 행렬 원소 값과 같은 위치에 있는 입력 영상 픽셀값을 서로 곱한 후, 그 결과를 모두 더하는 연산\n",
    "\n",
    "### 마스크 연산의 결과를 출력 영상에서 고정점 위치에 대응되는 픽셀 값으로 설정\n",
    "### 마스크 행렬 m의 중심이 입력 영상의 (x,y) 좌표 위에 위치 했을 떄 결과 영상의 픽셀 값 g(x,y)는 다음과 같이 연산\n",
    "\n",
    "### g(x,y) = m(0,0)f(x-1,y-1) + m(1,0)f(x,y-1) + m(2,0)f(x+1,y-1) +\n",
    "###               m(0,1)f(x-1,y) + m(1,1)f(x,y) + m(2,1)f(x+1,y) +\n",
    "###               m(0,2)f(x-1,y+1) + m(1,2)f(x,y+1) + m(2,2)f(x+1,y+1) \n",
    "\n",
    "## 가장자리 픽셀의 처리\n",
    "\n",
    "### 가장자리 픽셀에 대해 필터링을 수행할 때에는 특별한 처리가 필요하다. \n",
    "#### (가장자리 확장 방식 : Border Types 열거형 상수 사용) BORDER_REFLECT_101(DEFAULT), BORDER_CONSTANT, BORDER_REPLICATE, BORDER_REFLECT)\n",
    "\n",
    "## filter2D()함수 : 필터 마스크를 사용하는 필터링\n",
    "## filter2D(src, dst, ddepth, kernel, anchor, delta, bordertype)\n",
    "### src 영상에 kernel 필터를 이용하여 필터링을 수행하고, 그 결과를 dst에 저장.\n",
    "### 만약 src인자와 dst 인자에 같은 변수를 지정하면 필터링 결과를 입력 영상에 덮어쓰게 됨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 엠보싱 필터링\n",
    " \n",
    "### 엠보싱 필터는 입력 영상을 엠보싱 느낌을 나도록 변환                            -1 -1 0\n",
    "### 보통 입력 영상에서 픽셀 값 변화가 적은 평탄한 영역은 회색으로 설정   -1  0  1   대각선 방향으로 밝아지는 \n",
    "### 객체의 경계 부분은 좀 더 밝거나 어둡게 설정하면 엠보싱 느낌이 남        0  1  1\n",
    "\n",
    "### 대각선 방향으로 픽셀 값이 급격하게 변하는 부분에 필터링 수행 시 : 픽셀 값이 0보다 휠씬 크거나 0보다 휠씬 작은 값을 가지게 됨\n",
    "### 픽셀 값이 크게 바뀌지 않는 평탄한 영역에 필터링 수행 시 : 결과 영상의 픽셀값이 0에 가까운 값을 가지게 됨\n",
    "### 이를 그대로 화면에 나타낸다면 음수값은 포화연산에 의해 모두 0이 되어 입체감이 줄어든다. 엠보싱 필터를 구현 시 결과 영상에 128을 더하는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv.imread('field.bmp', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "if src is None:\n",
    "    print('Image loda failed!')\n",
    "    sys.exit()\n",
    "    \n",
    "emboss = np.array([[-1,-1,0],\n",
    "                  [-1,0,1],\n",
    "                  [0,1,1]], np.float32)\n",
    "\n",
    "dst=cv.filter2D(src, -1 ,emboss, delta=128)\n",
    "\n",
    "cv.imshow('src',src)\n",
    "cv.imshow('dst',dst)\n",
    "\n",
    "cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 블러링(Blurring)\n",
    "\n",
    "### 마치 초점이 맞지 않은 사진처럼 영상을 부드럽게 만드는 필터링 기법 smoothing(스무딩)이라고도 함\n",
    "### 영상에서 인접한 픽셀 간의 픽셀 값 변화가 크지 않은 경우 부드러운 느낌을 받을 수 있음\n",
    "### 블러링은 거친 느낌의 입력 영상을 부드럽게 만드는 용도로 사용되기도 하고, 혹은 입력 영상에 존재하는 잡음의 영향을 제거하는 전처리 과정으로 사용됨\n",
    "\n",
    "### 평균값 필터\n",
    "\n",
    "#### 입력 영상에서 특정 픽셀과 주변 픽셀들의 산술 평균을 결과 영상 픽셀 값으로 설정하는 필터\n",
    "#### 평균값 필터에 의해 생성되는 결과 영상은 픽셀 값의 급격한 변화가 줄어들어 날카로운 엣지가 무디어지고 잡음의 영향이 크게 사라지는 효과가 있음\n",
    "\n",
    "#### 각각의 행렬은 모두 원소 값이 1로 설정되어 있고, 행렬의 전체 원소 개수로 각 행렬 원소 값을 나누는 형태로 표한\n",
    "#### 평균값 필터는 마스크의 크기가 커지면 커질수록 더욱 부드러운 느낌의 결과 영상을 생성하며, 그 대신 연산량이 크게 증가할 수 있음.\n",
    "\n",
    "## blur()함수 : 평균값 필터링 수행\n",
    "### blur(src,dst,ksize,anchor,bordertype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulurring_mean() 함수는 3x3, 5x5, 7x7 크기의 평균값 필터를 이용하여 영상을 부드럽게 변환하고 출력한다.\n",
    "# 평균 값 필터의 크기가 커질수록 결과 영상이 더욱 부드럽게 변경됨\n",
    "\n",
    "def blurring_mean():\n",
    "    src=cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('failed!')\n",
    "        return\n",
    "    \n",
    "    cv.imshow('src',src)\n",
    "    \n",
    "    for ksize in range(3,9,2):\n",
    "        dst = cv.blur(src, (ksize, ksize))\n",
    "        \n",
    "        desc = \"Mean : %dx%d\" %(ksize,ksize)\n",
    "        cv.putText(dst, desc, (10,30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "                  1.0,255,1,cv.LINE_AA)\n",
    "        \n",
    "        cv.imshow('dst',dst)\n",
    "        cv.waitKey()\n",
    "        \n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "blurring_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가우시안 분포(정규 분포)\n",
    "\n",
    "### 가우시안 분포는 평균을 중심으로 좌우 대칭의 종 모양을 갖는 확률 분포\n",
    "### 자연계에서 발생하는 대부분의 사건이 가우시안 분포를 따름\n",
    "### 평균과 표준 편차에 따라 분포 모양이 결정됨. 표준 편차가 작으면 그래프가 뾰족한 형태, 표준 편차가 크면 완만한 형태\n",
    "### 영상의 가우시안 필터에서는 주로 평균이 0인 가우시안 분포함수를 사용\n",
    "\n",
    "### 2차원 가우시안 분포 함수로부터 마스크 행렬을 사용\n",
    "### 가우시안 분포함수는 연속 함수이지만 이산형의 마스크를 만들기 위해서 x와  y값이 정수인 위치에서만 가우시안 분포 함수 값을 추출하여 마스크를 생성. 이산형의 마스크를 만듬.\n",
    "\n",
    "### 필터 마스크를 이용하여 마스크 연산을 수행한다는 것은 필터링 대상 픽셀 근처에는 가중치를 크게 줌\n",
    "### 필터링 대상 픽셀과 멀리 떨어져 있는 주변부에는 가중치를 조금만 주어서 weight average(가중 평균)을 구하는 것과 동일\n",
    "\n",
    "### 가우시안 필터 마스크가 가중 평균을 구하기 위한 가중치 행렬 역할을 하는 것\n",
    "\n",
    "### 마스크 연산에 의한 영상 필터링은 마스크 크기가 커짐에 따라 연산량도 함께 증가\n",
    "\n",
    "### 마스크 행렬 크기가 9x9일 경우 한번의 마스크 연산시 81번의 곱셈 연산이 필요\n",
    "### 큰 표준 편차 값을 사용하면 마스크 크기도 함께 커지므로 연산 속도 측면에서 부담이 될 수 있음\n",
    "\n",
    "### 2차원 가우시안 분포함수는 1차원 가우시안 분포 함수의 곱을 분리할 수 있고, 이 특성을 이용하여 가우시안 필터 연산량을 크게 줄일 수 있음. 1차원 1x9 가우시안 마스크 행렬 g와 전치행렬 g^T 를 이용해서 필터링하면 2차원 가우시안 필터 마스크로 한번 필터링한 것과 같은 효과를 얻음. 연산횟수는 18번으로 감소하며 연산량이 크게 줄어 듬을 확인할 수 있음.\n",
    "\n",
    "\n",
    "## GaussianBlur() 함수 : 가우시안 필터링 수행\n",
    "### GaussianBlur(src, dst, ksize, sigmaX, sigmaY, borderType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "def blurring_gaussian():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('failed!')\n",
    "        return \n",
    "    \n",
    "    cv.imshow('src',src)\n",
    "    \n",
    "    for sigma in range(1,6):\n",
    "        dst = cv.GaussianBlur(src, (0,0), sigma)\n",
    "        \n",
    "        desc = \"Gaussian: sigma = %d\" %(sigma)\n",
    "        cv.putText(dst, desc, (10, 30), cv.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                  1.0, 255, 1, cv.LINE_AA)\n",
    "        \n",
    "        cv.imshow('dst',dst)\n",
    "        cv.waitKey()\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "blurring_gaussian()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 샤프닝 : 영상 날카롭게 하기\n",
    "## 언샤프 마스크 필터\n",
    "### sharpening(샤프닝)이란 영상을 날카로운 느낌이 나도록 변경하는 필터링 기법\n",
    "### 날카로운 느낌의 영상이란? 초점이 잘 맞는 사진처럼 객체의 윤곽이 뚜렷하게 구분되는 영상을 의미\n",
    "### 이미 촬영된 사진을 초점이 잘 맞는 사진처럼 보이게끔 변경하려면 영상 에지 근방에서 픽셀 값의 명암비가 커지도록 수정해야함\n",
    "### 샤프닝을 구현하기 위해 블러링도니 영상을 사용함\n",
    "### 블러링이 적용되어 부드러워진 영상을 활용하여 반대로 날까로운 영상을 생성\n",
    "### 블러링이 적용된 영상, 즉 날카롭지 않은 영상을 unsharp(언샤프)하다고 말하기도 함\n",
    "\n",
    "## 언샤프 마스크 필터의 동작 방식\n",
    "### f(x,y) : 원본 영상, f2(x,y) : 원본영상을 블러링 처리\n",
    "### g(x,y) = f(x,y) - f2(x,y) 원본 영상 - 블러링 처리 영상 (날카로운 성분만을 가지고 있는 함수)\n",
    "### h(x,y) = f(x,y) + a * g(x,y) 샤프닝 된 영상 = 원본영상 + g(x,y) (날카로운 성분만을 가지고 있는 함수)\n",
    "### a : 가중치, 실수 가중치를 곱한 후 더하면 날카로운 정도를 사용자가 조절 가능\n",
    "### a<1.0 : 조금 덜 날카로운 영상 a = 1.0 그대로\n",
    "### OpenCV는 함수를 따로 제공하고 있지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "### 영상을 다양한 표준 편차 값으로 가우시안 필터를 적용하고, 블러링된 영상을 이용하여 샤프닝 결과 영상을 생성\n",
    "### src 창에 나타난 영상은 입력 영상이고, dst 창에 나타난 영상은 다양한 sigma 값에 의해 생성된 언샤프 마스크 필터링 결과\n",
    "### dst 영상이 경계 부분이 좀 더 뚜렷하게 구분이 되는 것을 확인 가능\n",
    "### but, sigma 값이 커짐에 따라 다소 과장된 느낌의 샤프닝 결과 영상이 만들어질 가능성을 주의\n",
    "\n",
    "src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "cv.imshow('src',src)\n",
    "\n",
    "for sigma in range(1, 6):\n",
    "    blurred = cv.GaussianBlur(src, (0,0), sigma)\n",
    "    \n",
    "    alpha = 1.0\n",
    "    dst = cv.addWeighted(src, 1+alpha, blurred, -alpha, 0.0)\n",
    "    \n",
    "    desc = \"sigma: %d\" % sigma\n",
    "    cv.putText(dst, desc, (10,30), cv.FONT_HERSHEY_SIMPLEX, 1.0, 255, 1, cv.LINE_AA)\n",
    "    \n",
    "    cv.imshow('dst',dst)\n",
    "    cv.waitKey()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 잡음 제거 필터링\n",
    "## 영상과 잡음 모델\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "def noise_gaussian():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    cv. imshow('src',src)\n",
    "    \n",
    "    for stddev in [10,20,30]:\n",
    "        noise = np.zeros(src.shape,np.int32)\n",
    "        cv.randn(noise, 0, stddev)\n",
    "        \n",
    "        dst=cv.add(src, noise, dtype=cv.CV_8UC1)\n",
    "        \n",
    "        desc = 'stddev = %d' %stddev\n",
    "        cv.putText(dst, desc, (10,30), cv.FONT_HERSHEY_SIMPLEX,\n",
    "                  1.0, 255, 1, cv.LINE_AA)\n",
    "        cv.imshow('dst',dst)\n",
    "        cv.waitKey()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_gaussian()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 양방향 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_bilateral():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    noise = np.zeros(src.shape, np.int32)\n",
    "    cv.randn(noise ,0, 5)\n",
    "    cv.add(src, noise, src, dtype = cv.CV_8SC1)\n",
    "    \n",
    "    dst1 = cv.GaussianBlur(src, (0,0), 5)\n",
    "    dst2 = cv.bilateralFilter(src, -1, 10, 5)\n",
    "    \n",
    "    cv.imshow('src', src)\n",
    "    cv.imshow('dst1', dst1)\n",
    "    cv.imshow('dst2', dst2)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bilateral()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미디언 필터\n",
    "## 입력 영상에서 자기 자신 픽셀과 주변 픽셀 값 중에서 중간 값(median)을 선택하여 결과 영상 픽셀 값으로 설정하는 필터링 기법\n",
    "## 마스크 행렬과 입력 영상 픽셀 값을 서로 곱한 후 모두 더하는 형태의 연산을 사용하지 않음\n",
    "### 주변 픽셀 값들의 중간 값을 선택하기 위해 내부에서 픽셀값 정렬 과정이 사용됨\n",
    "## 미디언 필터는 특히 잡음 픽셀 값이 주변 픽셀 값과 큰 차이가 있는 경우에 효과적으로 동작함\n",
    "\n",
    "## 영상에 추가되는 잡음 중에 salt & pepper noise(소금&후추 잡음)은 픽셀값이 일정 확률로 0 또는 255로 변경되는 형태의 잡음\n",
    "## salt&pepper? => 잡음이 마치 소금과 후추 처럼 흰색 또는 검은 색으로 구성되기 때문\n",
    "## 소금 & 후추 잡음이 추가된 영상에 미디언 필터를 적용하면 대부분 소금 & 후추 잡음이 아닌 원본 영상에 존재하는 픽셀값이 중간값으로 선택되기 때문에 잡음은 효과적으로 제거됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def filter_median():\n",
    "    src = cv.imread('lena512.bmp', cv.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if src is None:\n",
    "        print('Image load failed!')\n",
    "        return \n",
    "    \n",
    "    for i in range(0, int(src.size /10)):\n",
    "        x= random.randint(0, src.shape[1]-1)\n",
    "        y= random.randint(0, src.shape[0]-1)\n",
    "        src[x,y]=(i%2)*255\n",
    "        \n",
    "    dst1=cv.GaussianBlur(src, (0,0),1)\n",
    "    dst2=cv.medianBlur(src, 3)\n",
    "    \n",
    "    cv.imshow('src',src)\n",
    "    cv.imshow('dst1',dst1)\n",
    "    cv.imshow('dst2',dst2)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어파인 변환 (affine Transformation)\n",
    "\n",
    "영상을 평행 이동시키거나 회전, 크기 변환 등을 통해 만들 수 있는 변환을 통칭\n",
    "영상을 한쪽 방향으로 밀어서 만든 것 같은 전단 변환도 어파인 변환에 포함\n",
    "직선은 그대로 직선으로 나타나고, 직선 간의 길이 비율과 평행 관계가 그대로 유지됨\n",
    "\n",
    "직사각형 형태의 영상은 어파인 변환에 의해 평행사변형에 해당하는 모양으로 변경됨\n",
    "\n",
    "\n",
    "\n",
    "입력 영상과 어파인 변환 결과 영상으로부터 어파인 변환 행렬을 구하기 위해서는 최소 세점의 이동 관계를 알아야 함\n",
    "점 하나의 이동 관계로부터 x,y 좌표에 대한 변환 수식 두개를 얻을 수 있으므로, 점 세개의 이동 관계로부터 총 여섯개의 방적식을 구할 수 있음.\n",
    "점 세 개의 이동 관계를 알고 있다면 여섯 개의 원소로 정의되는 어파인 변환 행렬을 구할 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "def affine_transform():\n",
    "    src = cv.imread('lena512.bmp')\n",
    "    \n",
    "    if src is None:\n",
    "        print('failed!')\n",
    "        return \n",
    "    \n",
    "    rows = src.shape[0]\n",
    "    cols = src.shape[1]\n",
    "    \n",
    "    src_pts = np.array([[0,0],\n",
    "                       [cols-1,0],\n",
    "                       [cols-1,rows-1]]).astype(np.float32)\n",
    "    \n",
    "    dst_pts = np.array([[50,50],\n",
    "                       [cols-100,100],\n",
    "                       [cols-50,rows-50]]).astype(np.float32)\n",
    "    \n",
    "    affine_mat = cv.getAffineTransform(src_pts, dst_pts)\n",
    "    dst = cv.warpAffine(src, affine_mat, (0,0))\n",
    "    \n",
    "    cv.imshow('src',src)\n",
    "    cv.imshow('dst',dst)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# affine_translation() 이동 변환\n",
    "잘린 부분이 생긴다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_translation():\n",
    "    src = cv.imread('lena512.bmp')\n",
    "    \n",
    "    if src is None:\n",
    "        print('failed')\n",
    "        return\n",
    "    \n",
    "    affine_mat = np.array([[1,0,150],\n",
    "                           [0,1,100]]).astype(np.float32)\n",
    "    \n",
    "    dst = cv.warpAffine(src, affine_mat, (0,0))\n",
    "    \n",
    "    cv.imshow('src',src)\n",
    "    cv.imshow('dst',dst)\n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_translation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전단 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크기 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회전 변환 (rotation transformation)\n",
    "\n",
    "## 특정 좌표를 기준으로 영상을 원하는 각도만큼 회전하는 변환\n",
    "\n",
    "## 영상의 회전 변환에 의해 입력 영상의 점 (x,y)가 이동하는 점의 좌표(x',y')는 다음과 같이 삼각함수를 이용하여 구할 수 있음\n",
    "\n",
    "## x' = cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
